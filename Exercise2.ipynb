{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 arrival airports in the world in 2013 (using the bookings file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_bookings = \"../Data/bookings.csv.bz2\"\r\n",
    "path_cleaned_bookings = \"../Data/cleaned_bookings.csv.bz2\"\r\n",
    "path_grouped_bookings = \"../Data/grouped_bookings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the file is so big (529 MB) that it can't fit in the memory of my computer, I read it in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_iter = pd.read_csv(\r\n",
    "    path_bookings,\r\n",
    "    compression='bz2',\r\n",
    "    engine='c',\r\n",
    "    chunksize=500000,\r\n",
    "    delimiter=\"^\",\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete duplicates (only first time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bookings = pd.DataFrame()\r\n",
    "\r\n",
    "for bookings_chunk in bookings_iter:\r\n",
    "    cleaned_bookings = (\r\n",
    "        cleaned_bookings\r\n",
    "        .append(bookings_chunk)\r\n",
    "        .drop_duplicates()\r\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1016377"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bookings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_bookings = (\r\n",
    "    cleaned_bookings\r\n",
    "    .apply(lambda col: col.str.strip() if col.dtypes == \"object\" else col)\r\n",
    "    .convert_dtypes()\r\n",
    "    .drop_duplicates()\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1016377"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_bookings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\r\n",
    "    cleaned_bookings\r\n",
    "    .rename(columns=str.strip)\r\n",
    "    .to_csv(path_cleaned_bookings, sep=\"^\", index=False)\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned data at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan action**\r\n",
    "1. Load cleaned data in one big chunk\r\n",
    "2. Fill NaNs with 0\r\n",
    "3. Covert columns to more suitable dtypes\r\n",
    "4. Group by *airport*\r\n",
    "5. Sum number of passengers\r\n",
    "6. Sort by number of passengers\r\n",
    "7. Get top 10 airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings = pd.read_csv(\r\n",
    "    path_cleaned_bookings,\r\n",
    "    compression='bz2',\r\n",
    "    engine='c',\r\n",
    "    delimiter=\"^\",\r\n",
    "    usecols=['arr_port', 'pax'],\r\n",
    "    dtype={'pax':'Int64'},\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_per_airport = (\r\n",
    "    cleaned_bookings\r\n",
    "    .fillna({'pax': 0})\r\n",
    "    .convert_dtypes()\r\n",
    "    #.rename(columns=str.strip)\r\n",
    "    .groupby([\"arr_port\"])\r\n",
    "    .agg(count=(\"pax\", np.sum))\r\n",
    "    .sort_values('count', ascending=False)\r\n",
    "    .reset_index()\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_per_airport.to_csv(path_grouped_bookings, sep=\"^\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Get top 10 airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<style  type=\"text/css\" >\n</style><table id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135d\" ><thead>    <tr>        <th class=\"col_heading level0 col0\" >Airport</th>        <th class=\"col_heading level0 col1\" >Total passengers</th>    </tr></thead><tbody>\n                <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow0_col0\" class=\"data row0 col0\" >LHR</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow0_col1\" class=\"data row0 col1\" >9040</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow1_col0\" class=\"data row1 col0\" >MCO</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow1_col1\" class=\"data row1 col1\" >7223</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow2_col0\" class=\"data row2 col0\" >LAX</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow2_col1\" class=\"data row2 col1\" >7191</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow3_col0\" class=\"data row3 col0\" >LAS</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow3_col1\" class=\"data row3 col1\" >7079</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow4_col0\" class=\"data row4 col0\" >JFK</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow4_col1\" class=\"data row4 col1\" >6788</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow5_col0\" class=\"data row5 col0\" >CDG</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow5_col1\" class=\"data row5 col1\" >6513</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow6_col0\" class=\"data row6 col0\" >BKK</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow6_col1\" class=\"data row6 col1\" >6006</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow7_col0\" class=\"data row7 col0\" >SFO</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow7_col1\" class=\"data row7 col1\" >5929</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow8_col0\" class=\"data row8 col0\" >MIA</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow8_col1\" class=\"data row8 col1\" >5896</td>\n            </tr>\n            <tr>\n                                <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow9_col0\" class=\"data row9 col0\" >DXB</td>\n                        <td id=\"T_47599798_2d7f_11eb_bda0_d07e35e8135drow9_col1\" class=\"data row9 col1\" >5647</td>\n            </tr>\n    </tbody></table>",
      "text/plain": "<pandas.io.formats.style.Styler at 0x175d4306d00>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\r\n",
    "    passengers_per_airport\r\n",
    "    .rename(columns={'arr_port': 'Airport', 'count': 'Total passengers'})\r\n",
    "    .head(10)\r\n",
    "    .style.hide_index()\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaned data in chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plan action**\r\n",
    "1. Load cleaned data in chunks \r\n",
    "2. Loop over all chunks and save the result\r\n",
    "    - Fill NaNs with 0\r\n",
    "    - Covert columns to more suitable dtypes\r\n",
    "    - Group by *airport*\r\n",
    "    - Sum number of passengers\r\n",
    "3. Manipulate the output of the previous step\r\n",
    "    - Group by *airport*\r\n",
    "    - Get top 10\r\n",
    "4. Save the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookings_iter2 = pd.read_csv(\r\n",
    "    path_cleaned_bookings,\r\n",
    "    compression='bz2',\r\n",
    "    engine='c',\r\n",
    "    chunksize=50000,\r\n",
    "    dtype={\"arr_port\": \"string\", \"pax\": 'Int64'},\r\n",
    "    usecols=[\"arr_port\", \"pax\"],\r\n",
    "    delimiter=\"^\",\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: groupby and sum within chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "passengers_per_airport2 = pd.DataFrame()\r\n",
    "\r\n",
    "for bookings_chunk in bookings_iter2:\r\n",
    "    grp = (\r\n",
    "        bookings_chunk\r\n",
    "        .fillna(0)\r\n",
    "        .convert_dtypes()\r\n",
    "        .rename(columns=str.strip)\r\n",
    "        .convert_dtypes()\r\n",
    "        .groupby([\"arr_port\"])\r\n",
    "        .agg(count=(\"pax\", np.sum))\r\n",
    "        .reset_index()\r\n",
    "    )\r\n",
    "\r\n",
    "    passengers_per_airport2 = passengers_per_airport2.append(grp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Airport</th>\n      <th>Total passengers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>LHR</td>\n      <td>9040</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MCO</td>\n      <td>7223</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LAX</td>\n      <td>7191</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LAS</td>\n      <td>7079</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>JFK</td>\n      <td>6788</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>CDG</td>\n      <td>6513</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>BKK</td>\n      <td>6006</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>SFO</td>\n      <td>5929</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>MIA</td>\n      <td>5896</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>DXB</td>\n      <td>5647</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  Airport  Total passengers\n0     LHR              9040\n1     MCO              7223\n2     LAX              7191\n3     LAS              7079\n4     JFK              6788\n5     CDG              6513\n6     BKK              6006\n7     SFO              5929\n8     MIA              5896\n9     DXB              5647"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = (\r\n",
    "    passengers_per_airport2\r\n",
    "    .groupby(['arr_port'])\r\n",
    "    .agg(count=(\"count\", np.sum))\r\n",
    "    .nlargest(10, 'count')\r\n",
    "    .reset_index()\r\n",
    "    .rename(columns={'arr_port': 'Airport', 'count': 'Total passengers'})\r\n",
    ")\r\n",
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.to_csv('top10_airports_per_passengers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}